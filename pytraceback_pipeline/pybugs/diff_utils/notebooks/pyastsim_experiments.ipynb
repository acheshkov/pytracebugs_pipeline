{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим датафрейм, который содержит версии функций до и после изменений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2529, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('scikit-learn_issues_functions_versions_newest.tsv', sep='\\t')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим фукнцию, на основе кода из pyastsim, которая будет считать получать normed_content из текста (а не из файла, как сделано в pyastsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import parse\n",
    "import astunparse\n",
    "from pyastsim.pyastsim import NormFunctions, NormIdentifiers\n",
    "from pyastsim.pyastsim import get_pair_stats\n",
    "\n",
    "\n",
    "def get_normed_content_for_src(filename, src, func=None):\n",
    "    tree = parse(src)\n",
    "\n",
    "    tree = NormFunctions(func=func).visit(tree)\n",
    "    tree = NormIdentifiers().visit(tree)\n",
    "\n",
    "    return (filename, astunparse.unparse(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почистим фукнции от комментариев и докстрингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(code):\n",
    "    lines = code.split('\\n')\n",
    "    return '\\n'.join([line for line in lines if not line.strip().startswith('#')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_body_regex = r'\\b(def [\\s\\S]+?)\\s+[\\\"\\']{3}[\\s\\S]+[\\\"\\']{3}\\n*(\\n.+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['before_merge_clean'] = data['before_merge'] \\\n",
    "    .apply(lambda x: remove_comments(re.sub(signature_body_regex, r'\\1\\2', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['after_merge_clean'] = data['after_merge'] \\\n",
    "    .apply(lambda x: remove_comments(re.sub(signature_body_regex, r'\\1\\2', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2529"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_sources = data[['before_merge_clean', 'after_merge_clean', 'function_name']].values\n",
    "len(func_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удалим лишние отступы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for func_index, (fs1, fs2, func_name) in enumerate(func_sources):\n",
    "    for version_index, fs in enumerate([fs1, fs2]):\n",
    "        fs_lines = fs.split('\\n')\n",
    "        indent = len(fs_lines[0]) - len(fs_lines[0].lstrip())\n",
    "\n",
    "        func_sources[func_index][version_index] = '\\n'.join([fs_line[indent:] for fs_line in fs_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fit(self, X, y):\n",
      "    if self.metric == 'precomputed':\n",
      "        raise ValueError(\"Precomputed is not supported.\")\n",
      "    if self.metric == 'manhattan':\n",
      "        X, y = self._validate_data(X, y, accept_sparse=['csc'])\n",
      "    else:\n",
      "        X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'])\n",
      "    is_X_sparse = sp.issparse(X)\n",
      "    if is_X_sparse and self.shrink_threshold:\n",
      "        raise ValueError(\"threshold shrinking not supported\"\n",
      "                         \" for sparse input\")\n",
      "    check_classification_targets(y)\n",
      "\n",
      "    n_samples, n_features = X.shape\n",
      "    le = LabelEncoder()\n",
      "    y_ind = le.fit_transform(y)\n",
      "    self.classes_ = classes = le.classes_\n",
      "    n_classes = classes.size\n",
      "    if n_classes < 2:\n",
      "        raise ValueError('The number of classes has to be greater than'\n",
      "                         ' one; got %d class' % (n_classes))\n",
      "\n",
      "    self.centroids_ = np.empty((n_classes, n_features), dtype=np.float64)\n",
      "    nk = np.zeros(n_classes)\n",
      "\n",
      "    for cur_class in range(n_classes):\n",
      "        center_mask = y_ind == cur_class\n",
      "        nk[cur_class] = np.sum(center_mask)\n",
      "        if is_X_sparse:\n",
      "            center_mask = np.where(center_mask)[0]\n",
      "\n",
      "        if self.metric == \"manhattan\":\n",
      "            if not is_X_sparse:\n",
      "                self.centroids_[cur_class] = np.median(X[center_mask], axis=0)\n",
      "            else:\n",
      "                self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])\n",
      "        else:\n",
      "            if self.metric != 'euclidean':\n",
      "                warnings.warn(\"Averaging for metrics other than \"\n",
      "                              \"euclidean and manhattan not supported. \"\n",
      "                              \"The average is set to be the mean.\"\n",
      "                              )\n",
      "            self.centroids_[cur_class] = X[center_mask].mean(axis=0)\n",
      "\n",
      "    if self.shrink_threshold:\n",
      "        dataset_centroid_ = np.mean(X, axis=0)\n",
      "\n",
      "        m = np.sqrt((1. / nk) - (1. / n_samples))\n",
      "        variance = (X - self.centroids_[y_ind]) ** 2\n",
      "        variance = variance.sum(axis=0)\n",
      "        s = np.sqrt(variance / (n_samples - n_classes))\n",
      "        s += np.median(s)  # To deter outliers from affecting the results.\n",
      "        mm = m.reshape(len(m), 1)  # Reshape to allow broadcasting.\n",
      "        ms = mm * s\n",
      "        deviation = ((self.centroids_ - dataset_centroid_) / ms)\n",
      "        signs = np.sign(deviation)\n",
      "        deviation = (np.abs(deviation) - self.shrink_threshold)\n",
      "        np.clip(deviation, 0, None, out=deviation)\n",
      "        deviation *= signs\n",
      "        msd = ms * deviation\n",
      "        self.centroids_ = dataset_centroid_[np.newaxis, :] + msd\n",
      "    return self\n",
      "\n",
      "def fit(self, X, y):\n",
      "    if self.metric == 'precomputed':\n",
      "        raise ValueError(\"Precomputed is not supported.\")\n",
      "    if self.metric == 'manhattan':\n",
      "        X, y = self._validate_data(X, y, accept_sparse=['csc'])\n",
      "    else:\n",
      "        X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'])\n",
      "    is_X_sparse = sp.issparse(X)\n",
      "    if is_X_sparse and self.shrink_threshold:\n",
      "        raise ValueError(\"threshold shrinking not supported\"\n",
      "                         \" for sparse input\")\n",
      "    check_classification_targets(y)\n",
      "\n",
      "    n_samples, n_features = X.shape\n",
      "    le = LabelEncoder()\n",
      "    y_ind = le.fit_transform(y)\n",
      "    self.classes_ = classes = le.classes_\n",
      "    n_classes = classes.size\n",
      "    if n_classes < 2:\n",
      "        raise ValueError('The number of classes has to be greater than'\n",
      "                         ' one; got %d class' % (n_classes))\n",
      "\n",
      "    self.centroids_ = np.empty((n_classes, n_features), dtype=np.float64)\n",
      "    nk = np.zeros(n_classes)\n",
      "\n",
      "    for cur_class in range(n_classes):\n",
      "        center_mask = y_ind == cur_class\n",
      "        nk[cur_class] = np.sum(center_mask)\n",
      "        if is_X_sparse:\n",
      "            center_mask = np.where(center_mask)[0]\n",
      "\n",
      "        if self.metric == \"manhattan\":\n",
      "            if not is_X_sparse:\n",
      "                self.centroids_[cur_class] = np.median(X[center_mask], axis=0)\n",
      "            else:\n",
      "                self.centroids_[cur_class] = csc_median_axis_0(X[center_mask])\n",
      "        else:\n",
      "            if self.metric != 'euclidean':\n",
      "                warnings.warn(\"Averaging for metrics other than \"\n",
      "                              \"euclidean and manhattan not supported. \"\n",
      "                              \"The average is set to be the mean.\"\n",
      "                              )\n",
      "            self.centroids_[cur_class] = X[center_mask].mean(axis=0)\n",
      "\n",
      "    if self.shrink_threshold:\n",
      "        if np.all(np.ptp(X, axis=0) == 0):\n",
      "            raise ValueError(\"All features have zero variance. \"\n",
      "                             \"Division by zero.\")\n",
      "        dataset_centroid_ = np.mean(X, axis=0)\n",
      "\n",
      "        m = np.sqrt((1. / nk) - (1. / n_samples))\n",
      "        variance = (X - self.centroids_[y_ind]) ** 2\n",
      "        variance = variance.sum(axis=0)\n",
      "        s = np.sqrt(variance / (n_samples - n_classes))\n",
      "        s += np.median(s)  # To deter outliers from affecting the results.\n",
      "        mm = m.reshape(len(m), 1)  # Reshape to allow broadcasting.\n",
      "        ms = mm * s\n",
      "        deviation = ((self.centroids_ - dataset_centroid_) / ms)\n",
      "        signs = np.sign(deviation)\n",
      "        deviation = (np.abs(deviation) - self.shrink_threshold)\n",
      "        np.clip(deviation, 0, None, out=deviation)\n",
      "        deviation *= signs\n",
      "        msd = ms * deviation\n",
      "        self.centroids_ = dataset_centroid_[np.newaxis, :] + msd\n",
      "    return self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(func_sources[0][0])\n",
    "print(func_sources[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['similarity'] = np.nan\n",
    "data['distance'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca0738dcf5148798392b919813fb4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2529), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in func check_transformer_preserve_dtypes, index: 61, error: unexpected EOF while parsing (<unknown>, line 23)\n",
      "Error in func _argmax, index: 661, error: invalid syntax (<unknown>, line 3)\n",
      "Error in func _argmax, index: 662, error: invalid syntax (<unknown>, line 3)\n",
      "Error in func _get_column_indices, index: 924, error: unexpected EOF while parsing (<unknown>, line 38)\n",
      "Error in func _get_column_indices, index: 925, error: unexpected EOF while parsing (<unknown>, line 38)\n",
      "Error in func _object_dtype_isnan, index: 938, error: invalid syntax (<unknown>, line 3)\n",
      "Error in func _get_column_indices, index: 1197, error: unexpected EOF while parsing (<unknown>, line 41)\n",
      "Error in func _get_column_indices, index: 1205, error: unexpected EOF while parsing (<unknown>, line 41)\n",
      "Error in func CloudPickler.dump, index: 1253, error: invalid syntax (<unknown>, line 7)\n",
      "Error in func CloudPickler.dump, index: 1308, error: invalid syntax (<unknown>, line 7)\n",
      "Error in func concurrency_safe_rename, index: 1400, error: invalid syntax (<unknown>, line 18)\n",
      "Error in func Parallel.retrieve, index: 1440, error: EOF while scanning triple-quoted string literal (<unknown>, line 40)\n",
      "Error in func _solve_sparse_cg.create_mv, index: 1704, error: invalid syntax (<unknown>, line 5)\n",
      "Error in func _solve_sparse_cg.create_mv, index: 1706, error: invalid syntax (<unknown>, line 5)\n",
      "Error in func BaseSearchCV.fit, index: 1778, error: unindent does not match any outer indentation level (<unknown>, line 20)\n",
      "Error in func BaseSearchCV.fit, index: 1782, error: unindent does not match any outer indentation level (<unknown>, line 20)\n",
      "Error in func BaseSearchCV._fit, index: 1961, error: unindent does not match any outer indentation level (<unknown>, line 20)\n",
      "Error in func BaseSearchCV._fit, index: 1967, error: unindent does not match any outer indentation level (<unknown>, line 20)\n",
      "Error in func BaseSearchCV._fit, index: 2194, error: unindent does not match any outer indentation level (<unknown>, line 20)\n",
      "Error in func BaseSearchCV._fit, index: 2195, error: unindent does not match any outer indentation level (<unknown>, line 20)\n",
      "Error in func Parallel.dispatch_next, index: 2462, error: invalid syntax (<unknown>, line 2)\n",
      "Error in func Parallel.dispatch_next, index: 2469, error: invalid syntax (<unknown>, line 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (fs1, fs2, func_name) in enumerate(tqdm(func_sources)):\n",
    "    try:\n",
    "        submissions = [get_normed_content_for_src(f'{func_name}_{i}', f) for i, f in enumerate([fs1, fs2])]\n",
    "\n",
    "        pairs = [get_pair_stats(pair) for pair in itertools.combinations(submissions, 2)]\n",
    "        pairs.sort(key=lambda a: -a[0])\n",
    "        for sim, dld, a, b in pairs:\n",
    "#             print(f\"Detected pair similarity of {int(sim)}% with edit distance of {dld} for {a[0]} and {b[0]}\\n\")\n",
    "            data.loc[i, 'similarity'] = int(sim)\n",
    "            data.loc[i, 'distance'] = dld\n",
    "    except SyntaxError as e:\n",
    "        print(f'Error in func {func_name}, index: {i}, error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4964724a8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.similarity.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['before_merge_clean'] == data['after_merge_clean']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['similarity'] == 100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simialrity_notnull_mask = (data['similarity'].notnull())\n",
    "similarity_100_mask = (data['similarity'] == 100)\n",
    "equals_code_mask = (data['before_merge_clean'] == data['after_merge_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[equals_code_mask & ~similarity_100_mask  & simialrity_notnull_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[~equals_code_mask & similarity_100_mask & simialrity_notnull_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _init_counters(self, n_effective_classes, n_features):\n",
      "        self.class_count_ = np.zeros(n_effective_classes, dtype=np.float64)\n",
      "        self.feature_count_ = np.zeros((n_effective_classes, n_features),\n",
      "                                       dtype=np.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[~equals_code_mask & similarity_100_mask & simialrity_notnull_mask].iloc[0]['before_merge_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _init_counters(self, n_classes, n_features):\n",
      "        self.class_count_ = np.zeros(n_classes, dtype=np.float64)\n",
      "        self.feature_count_ = np.zeros((n_classes, n_features),\n",
      "                                       dtype=np.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[~equals_code_mask & similarity_100_mask & simialrity_notnull_mask].iloc[0]['after_merge_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на синтетических примерах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_sources = [\n",
    "    [\n",
    "        'def a(b, c, d):\\n    x = b + c\\n    y = c + d\\n    z = x + y\\n    return z', \n",
    "        'def b(c, d, e):\\n    x = c + d\\n    y = d + e\\n    z = x + y\\n    return z',\n",
    "        'names_changed'\n",
    "    ],\n",
    "    [\n",
    "        'def a(b, c, d):\\n    y = c + d\\n    x = b + c\\n    z = x + y\\n    return z', \n",
    "        'def b(c, d, e):\\n    x = c + d\\n    y = d + e\\n    z = x + y\\n    return z',\n",
    "        'lines_order_changed'\n",
    "    ],\n",
    "    [\n",
    "        'def a(b, c, d):\\n    y = c + d\\n    x = b + c\\n    z = x + y\\n    return z', \n",
    "        'def b(c, d, e):\\n    x = c + d\\n    y = e + d\\n    z = x + y\\n    return z',\n",
    "        'lines_order_and_operation_arguments_changed'\n",
    "    ],\n",
    "    [\n",
    "        'def a(b, c, d):\\n    x = b + c\\n    y = c + d\\n    z = x + y\\n    return z', \n",
    "        'def b(c, d, e):\\n    x = c + d\\n    y = d + e\\n    z = x - y\\n    return z',\n",
    "        'operation_changed'\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5882c5f6f9481ca8812dbcbd8358e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected pair similarity of 100% with edit distance of 0 for names_changed_0 and names_changed_1\n",
      "\n",
      "Detected pair similarity of 96% with edit distance of 4 for lines_order_changed_0 and lines_order_changed_1\n",
      "\n",
      "Detected pair similarity of 97% with edit distance of 3 for lines_order_and_operation_arguments_changed_0 and lines_order_and_operation_arguments_changed_1\n",
      "\n",
      "Detected pair similarity of 99% with edit distance of 1 for operation_changed_0 and operation_changed_1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (fs1, fs2, func_name) in enumerate(tqdm(func_sources)):\n",
    "    try:\n",
    "        submissions = [get_normed_content_for_src(f'{func_name}_{i}', f) for i, f in enumerate([fs1, fs2])]\n",
    "\n",
    "        pairs = [get_pair_stats(pair) for pair in itertools.combinations(submissions, 2)]\n",
    "        pairs.sort(key=lambda a: -a[0])\n",
    "        for sim, dld, a, b in pairs:\n",
    "            print(f\"Detected pair similarity of {int(sim)}% with edit distance of {dld} for {a[0]} and {b[0]}\\n\")\n",
    "    except SyntaxError as e:\n",
    "        print(f'Error in func {func_name}, index: {i}, error: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
