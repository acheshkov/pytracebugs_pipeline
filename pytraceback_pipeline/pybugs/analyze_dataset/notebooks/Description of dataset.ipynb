{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "headed-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-cylinder",
   "metadata": {},
   "source": [
    "# Описание датасета\n",
    "\n",
    "Датасет состоит из нескольких частей:\n",
    "\n",
    "- датасет со сниппетами кода, содержащими ошибки (`buggy_dataset.rar`)\n",
    "- датасет со сниппетами, содержащими корректный код (`correct_dataset.rar`)\n",
    "\n",
    "Датасет с кодом внутри каждого архива разбит на части:\n",
    "\n",
    "- обучающая выборка (`bugfixes_train.pickle` и `correct_source_code_train.pickle`)\n",
    "- валидационная выборка (`bugfixes_valid.pickle` и `correct_source_code_valid.pickle`)\n",
    "- тестовая выборка (`bugfixes_test.pickle` и `correct_source_code_test.pickle`).\n",
    "\n",
    "Сниппеты кода берутся из репозиториев из GitHub. Репозитории, представленные в тестовой выборке, не представлены в обучающей выборке, однако представлены в валидационной выборке.\n",
    "\n",
    "В дополнение к исходному тексту сниппетов, их исходный код также содержатся в виде файлов в прилагаемых архивах `buggy_snippets_files.rar` и `stable_snippets_files.rar`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-college",
   "metadata": {},
   "source": [
    "# Загрузка данных датасетов\n",
    "\n",
    "Загрузим, например, обучающую выборку из датасета со сниппетами, содержащими ошибки (файл `bugfixes_train.pickle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serious-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_buggy_data = '/home/kks/zephyr_data/buggy_code/'\n",
    "bugfixes_train = pd.read_pickle(path_to_buggy_data + 'bugfixes_train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-promotion",
   "metadata": {},
   "source": [
    "# Описание датасета с кодом с ошибками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-unemployment",
   "metadata": {},
   "source": [
    "Покажем список колонок таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "august-disaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['after_merge', 'before_merge', 'commit_message', 'commit_sha',\n",
       "       'commit_summary', 'commit_type', 'filename',\n",
       "       'full_file_code_after_merge', 'full_file_code_before_merge',\n",
       "       'function_name', 'url', 'merge_commit_sha', 'pr_type', 'pr_url',\n",
       "       'title', 'bodyHTML', 'bug report', 'closedAt', 'createdAt',\n",
       "       'publishedAt', 'author', 'labels',\n",
       "       'referencing commits not linked to PRs',\n",
       "       'referencing commits linked to PRs',\n",
       "       'closing commits not linked to PRs', 'closing commits linked to PRs',\n",
       "       'closing PRs', 'linked PRs', 'mentioning PRs',\n",
       "       'PRs for referencing commits', 'duplicate',\n",
       "       'has mentioning, linked or closing PRs', 'has related commits and PRs',\n",
       "       'source code and errors', 'keyword closing PRs', 'non-closing PRs',\n",
       "       'relevant non-closing PRs', 'all relevant PRs', 'most relevant PRs',\n",
       "       'keyword closing commits', 'non-closing commits',\n",
       "       'relevant non-closing commits', 'all relevant commits',\n",
       "       'most relevant commits', 'full_traceback', 'traceback_type',\n",
       "       'before_merge_without_docstrings', 'after_merge_without_docstrings',\n",
       "       'before_merge_docstrings', 'after_merge_docstrings',\n",
       "       'path_to_snippet_before_merge', 'path_to_snippet_after_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfixes_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-converter",
   "metadata": {},
   "source": [
    "В колонках `after_merge` и `before_merge` содержится исходный код сниппетов с ошибками после их исправления и до их исправления. Иными словами, в колонке `before_merge` содержатся исходный текст сниппетов кода с ошибками, а в колонке `after_merge` - исходный текст этих сниппетов сразу после исправления ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automotive-terrace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after_merge</th>\n",
       "      <th>before_merge</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>commit_sha</th>\n",
       "      <th>commit_summary</th>\n",
       "      <th>commit_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>full_file_code_after_merge</th>\n",
       "      <th>full_file_code_before_merge</th>\n",
       "      <th>function_name</th>\n",
       "      <th>...</th>\n",
       "      <th>all relevant commits</th>\n",
       "      <th>most relevant commits</th>\n",
       "      <th>full_traceback</th>\n",
       "      <th>traceback_type</th>\n",
       "      <th>before_merge_without_docstrings</th>\n",
       "      <th>after_merge_without_docstrings</th>\n",
       "      <th>before_merge_docstrings</th>\n",
       "      <th>after_merge_docstrings</th>\n",
       "      <th>path_to_snippet_before_merge</th>\n",
       "      <th>path_to_snippet_after_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>@cli.command()\\n@click.argument('result_pickle...</td>\n",
       "      <td>@cli.command()\\n@click.argument('result_pickle...</td>\n",
       "      <td>fix https://github.com/ricequant/rqalpha/issue...</td>\n",
       "      <td>32e70a06c7ca62c5c2b4adf5150e01e1cd33eee1</td>\n",
       "      <td>fix https://github.com/ricequant/rqalpha/issue...</td>\n",
       "      <td>most relevant commits</td>\n",
       "      <td>rqalpha/mod/rqalpha_mod_sys_analyser/__init__.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n#\\n# Copyright 2017 R...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n#\\n# Copyright 2017 R...</td>\n",
       "      <td>plot</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'commitUrl': 'https://github.com/ricequant/r...</td>\n",
       "      <td>[{'commitUrl': 'https://github.com/ricequant/r...</td>\n",
       "      <td>Traceback (most recent call last):\\nFile \"c:\\p...</td>\n",
       "      <td>TypeError</td>\n",
       "      <td>@cli.command()\\n@click.argument('result_pickle...</td>\n",
       "      <td>@cli.command()\\n@click.argument('result_pickle...</td>\n",
       "      <td>[[sys_analyser] draw result DataFrame]</td>\n",
       "      <td>[[sys_analyser] draw result DataFrame]</td>\n",
       "      <td>buggy_snippets_files/1b26d646e62a8d394be4573db...</td>\n",
       "      <td>buggy_snippets_files/1b26d646e62a8d394be4573db...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>def stream_logs(self):\\n    \"\"\"Stream a pod's ...</td>\n",
       "      <td>def stream_logs(self):\\n    \"\"\"Stream a pod's ...</td>\n",
       "      <td>Merge pull request #185 from minrk/avoid-failu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merge pull request #185 from minrk/avoid-failure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>binderhub/build.py</td>\n",
       "      <td>\"\"\"\\nContains build of a docker image from a g...</td>\n",
       "      <td>\"\"\"\\nContains build of a docker image from a g...</td>\n",
       "      <td>Build.stream_logs</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>/ # jupyter-repo2docker https://github.com/yuv...</td>\n",
       "      <td>FileNotFoundError</td>\n",
       "      <td>def stream_logs(self):\\n    \\n    for line in ...</td>\n",
       "      <td>def stream_logs(self):\\n    \\n    for line in ...</td>\n",
       "      <td>[Stream a pod's log.]</td>\n",
       "      <td>[Stream a pod's log.]</td>\n",
       "      <td>buggy_snippets_files/e140d339be68a93ae4918849a...</td>\n",
       "      <td>buggy_snippets_files/e140d339be68a93ae4918849a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24555</th>\n",
       "      <td>@Slot(str)\\ndef addRecentProjectFile(self, pro...</td>\n",
       "      <td>@Slot(str)\\ndef addRecentProjectFile(self, pro...</td>\n",
       "      <td>Merge pull request #940 from ChemicalXandco/fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merge pull request #940 from ChemicalXandco/fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meshroom/ui/app.py</td>\n",
       "      <td>import logging\\nimport os\\nimport argparse\\n\\n...</td>\n",
       "      <td>import logging\\nimport os\\nimport argparse\\n\\n...</td>\n",
       "      <td>MeshroomApp.addRecentProjectFile</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2020-05-23 16:12:48,660][ERROR] Traceback (mo...</td>\n",
       "      <td>OSError</td>\n",
       "      <td>@Slot(str)\\ndef addRecentProjectFile(self, pro...</td>\n",
       "      <td>@Slot(str)\\ndef addRecentProjectFile(self, pro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>buggy_snippets_files/7045396915b1950e5d4c0d015...</td>\n",
       "      <td>buggy_snippets_files/7045396915b1950e5d4c0d015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24559</th>\n",
       "      <td>def addSfmAugmentation(self, withMVS=False):\\n...</td>\n",
       "      <td>def addSfmAugmentation(self, withMVS=False):\\n...</td>\n",
       "      <td>Merge pull request #140 from alicevision/fix_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Merge pull request #140 from alicevision/fix_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meshroom/ui/reconstruction.py</td>\n",
       "      <td>import logging\\nimport os\\nfrom threading impo...</td>\n",
       "      <td>import logging\\nimport os\\nfrom threading impo...</td>\n",
       "      <td>Reconstruction.addSfmAugmentation</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Traceback (most recent call last):\\nFile \"C:\\U...</td>\n",
       "      <td>RuntimeError</td>\n",
       "      <td>def addSfmAugmentation(self, withMVS=False):\\n...</td>\n",
       "      <td>def addSfmAugmentation(self, withMVS=False):\\n...</td>\n",
       "      <td>[Create a new augmentation step connected to t...</td>\n",
       "      <td>[Create a new augmentation step connected to t...</td>\n",
       "      <td>buggy_snippets_files/6e34b43028572a05882fee2a8...</td>\n",
       "      <td>buggy_snippets_files/6e34b43028572a05882fee2a8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26152</th>\n",
       "      <td>def load_pymathics_doc(self):\\n    if self.pym...</td>\n",
       "      <td>def load_pymathics_doc(self):\\n    if self.pym...</td>\n",
       "      <td>Fixed #906\\n</td>\n",
       "      <td>b2602cc15c6dd93b676031dc6efd3b4f5c4b084e</td>\n",
       "      <td>Fixed #906</td>\n",
       "      <td>most relevant commits</td>\n",
       "      <td>mathics/doc/doc.py</td>\n",
       "      <td>#!/usr/bin/env python3\\n# -*- coding: utf-8 -*...</td>\n",
       "      <td>#!/usr/bin/env python3\\n# -*- coding: utf-8 -*...</td>\n",
       "      <td>MathicsMainDocumentation.load_pymathics_doc</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'commitUrl': 'https://github.com/mathics/Mat...</td>\n",
       "      <td>[{'commitUrl': 'https://github.com/mathics/Mat...</td>\n",
       "      <td>$ mathicsserver\\nwarning: database file /home/...</td>\n",
       "      <td>KeyError</td>\n",
       "      <td>def load_pymathics_doc(self):\\n    if self.pym...</td>\n",
       "      <td>def load_pymathics_doc(self):\\n    if self.pym...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>buggy_snippets_files/022d3bdc74ccf0463b864bf1e...</td>\n",
       "      <td>buggy_snippets_files/022d3bdc74ccf0463b864bf1e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             after_merge  \\\n",
       "1909   @cli.command()\\n@click.argument('result_pickle...   \n",
       "2568   def stream_logs(self):\\n    \"\"\"Stream a pod's ...   \n",
       "24555  @Slot(str)\\ndef addRecentProjectFile(self, pro...   \n",
       "24559  def addSfmAugmentation(self, withMVS=False):\\n...   \n",
       "26152  def load_pymathics_doc(self):\\n    if self.pym...   \n",
       "\n",
       "                                            before_merge  \\\n",
       "1909   @cli.command()\\n@click.argument('result_pickle...   \n",
       "2568   def stream_logs(self):\\n    \"\"\"Stream a pod's ...   \n",
       "24555  @Slot(str)\\ndef addRecentProjectFile(self, pro...   \n",
       "24559  def addSfmAugmentation(self, withMVS=False):\\n...   \n",
       "26152  def load_pymathics_doc(self):\\n    if self.pym...   \n",
       "\n",
       "                                          commit_message  \\\n",
       "1909   fix https://github.com/ricequant/rqalpha/issue...   \n",
       "2568   Merge pull request #185 from minrk/avoid-failu...   \n",
       "24555  Merge pull request #940 from ChemicalXandco/fi...   \n",
       "24559  Merge pull request #140 from alicevision/fix_l...   \n",
       "26152                                       Fixed #906\\n   \n",
       "\n",
       "                                     commit_sha  \\\n",
       "1909   32e70a06c7ca62c5c2b4adf5150e01e1cd33eee1   \n",
       "2568                                        NaN   \n",
       "24555                                       NaN   \n",
       "24559                                       NaN   \n",
       "26152  b2602cc15c6dd93b676031dc6efd3b4f5c4b084e   \n",
       "\n",
       "                                          commit_summary  \\\n",
       "1909   fix https://github.com/ricequant/rqalpha/issue...   \n",
       "2568    Merge pull request #185 from minrk/avoid-failure   \n",
       "24555  Merge pull request #940 from ChemicalXandco/fi...   \n",
       "24559  Merge pull request #140 from alicevision/fix_l...   \n",
       "26152                                         Fixed #906   \n",
       "\n",
       "                 commit_type  \\\n",
       "1909   most relevant commits   \n",
       "2568                     NaN   \n",
       "24555                    NaN   \n",
       "24559                    NaN   \n",
       "26152  most relevant commits   \n",
       "\n",
       "                                               filename  \\\n",
       "1909   rqalpha/mod/rqalpha_mod_sys_analyser/__init__.py   \n",
       "2568                                 binderhub/build.py   \n",
       "24555                                meshroom/ui/app.py   \n",
       "24559                     meshroom/ui/reconstruction.py   \n",
       "26152                                mathics/doc/doc.py   \n",
       "\n",
       "                              full_file_code_after_merge  \\\n",
       "1909   # -*- coding: utf-8 -*-\\n#\\n# Copyright 2017 R...   \n",
       "2568   \"\"\"\\nContains build of a docker image from a g...   \n",
       "24555  import logging\\nimport os\\nimport argparse\\n\\n...   \n",
       "24559  import logging\\nimport os\\nfrom threading impo...   \n",
       "26152  #!/usr/bin/env python3\\n# -*- coding: utf-8 -*...   \n",
       "\n",
       "                             full_file_code_before_merge  \\\n",
       "1909   # -*- coding: utf-8 -*-\\n#\\n# Copyright 2017 R...   \n",
       "2568   \"\"\"\\nContains build of a docker image from a g...   \n",
       "24555  import logging\\nimport os\\nimport argparse\\n\\n...   \n",
       "24559  import logging\\nimport os\\nfrom threading impo...   \n",
       "26152  #!/usr/bin/env python3\\n# -*- coding: utf-8 -*...   \n",
       "\n",
       "                                     function_name  ...  \\\n",
       "1909                                          plot  ...   \n",
       "2568                             Build.stream_logs  ...   \n",
       "24555             MeshroomApp.addRecentProjectFile  ...   \n",
       "24559            Reconstruction.addSfmAugmentation  ...   \n",
       "26152  MathicsMainDocumentation.load_pymathics_doc  ...   \n",
       "\n",
       "                                    all relevant commits  \\\n",
       "1909   [{'commitUrl': 'https://github.com/ricequant/r...   \n",
       "2568                                                  []   \n",
       "24555                                                 []   \n",
       "24559                                                 []   \n",
       "26152  [{'commitUrl': 'https://github.com/mathics/Mat...   \n",
       "\n",
       "                                   most relevant commits  \\\n",
       "1909   [{'commitUrl': 'https://github.com/ricequant/r...   \n",
       "2568                                                  []   \n",
       "24555                                                 []   \n",
       "24559                                                 []   \n",
       "26152  [{'commitUrl': 'https://github.com/mathics/Mat...   \n",
       "\n",
       "                                          full_traceback     traceback_type  \\\n",
       "1909   Traceback (most recent call last):\\nFile \"c:\\p...          TypeError   \n",
       "2568   / # jupyter-repo2docker https://github.com/yuv...  FileNotFoundError   \n",
       "24555  [2020-05-23 16:12:48,660][ERROR] Traceback (mo...            OSError   \n",
       "24559  Traceback (most recent call last):\\nFile \"C:\\U...       RuntimeError   \n",
       "26152  $ mathicsserver\\nwarning: database file /home/...           KeyError   \n",
       "\n",
       "                         before_merge_without_docstrings  \\\n",
       "1909   @cli.command()\\n@click.argument('result_pickle...   \n",
       "2568   def stream_logs(self):\\n    \\n    for line in ...   \n",
       "24555  @Slot(str)\\ndef addRecentProjectFile(self, pro...   \n",
       "24559  def addSfmAugmentation(self, withMVS=False):\\n...   \n",
       "26152  def load_pymathics_doc(self):\\n    if self.pym...   \n",
       "\n",
       "                          after_merge_without_docstrings  \\\n",
       "1909   @cli.command()\\n@click.argument('result_pickle...   \n",
       "2568   def stream_logs(self):\\n    \\n    for line in ...   \n",
       "24555  @Slot(str)\\ndef addRecentProjectFile(self, pro...   \n",
       "24559  def addSfmAugmentation(self, withMVS=False):\\n...   \n",
       "26152  def load_pymathics_doc(self):\\n    if self.pym...   \n",
       "\n",
       "                                 before_merge_docstrings  \\\n",
       "1909              [[sys_analyser] draw result DataFrame]   \n",
       "2568                               [Stream a pod's log.]   \n",
       "24555                                                 []   \n",
       "24559  [Create a new augmentation step connected to t...   \n",
       "26152                                                 []   \n",
       "\n",
       "                                  after_merge_docstrings  \\\n",
       "1909              [[sys_analyser] draw result DataFrame]   \n",
       "2568                               [Stream a pod's log.]   \n",
       "24555                                                 []   \n",
       "24559  [Create a new augmentation step connected to t...   \n",
       "26152                                                 []   \n",
       "\n",
       "                            path_to_snippet_before_merge  \\\n",
       "1909   buggy_snippets_files/1b26d646e62a8d394be4573db...   \n",
       "2568   buggy_snippets_files/e140d339be68a93ae4918849a...   \n",
       "24555  buggy_snippets_files/7045396915b1950e5d4c0d015...   \n",
       "24559  buggy_snippets_files/6e34b43028572a05882fee2a8...   \n",
       "26152  buggy_snippets_files/022d3bdc74ccf0463b864bf1e...   \n",
       "\n",
       "                             path_to_snippet_after_merge  \n",
       "1909   buggy_snippets_files/1b26d646e62a8d394be4573db...  \n",
       "2568   buggy_snippets_files/e140d339be68a93ae4918849a...  \n",
       "24555  buggy_snippets_files/7045396915b1950e5d4c0d015...  \n",
       "24559  buggy_snippets_files/6e34b43028572a05882fee2a8...  \n",
       "26152  buggy_snippets_files/022d3bdc74ccf0463b864bf1e...  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfixes_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-resident",
   "metadata": {},
   "source": [
    "Колонки с названиями `filename` и `function_name` содержат локализацию сниппета, т.е. название файла, где он содержится, а также название функции или метода соответственно. Колонки с названиями `full_file_code_after_merge` и `full_file_code_before_merge` содержат текст модуля, содержащего соответствующий сниппет после и до исправления (`after_merge` и `before_merge`). Колонки `commit_message`, `commit_sha` и `commit_summary` содержат информацию по коммитам (но не мердж-коммитам пулл-реквестов), из которых берутся исправления. Колонка `url` содержит ссылку на страницу инцидента, ассоциированного с данным исправлением. Колонки `title`, `bodyHTML`, `bug report`, `closedAt`, `createdAt`, `publishedAt`, `author` и `labels` содержат информацию о названии инцидента, тексте описания ошибки в разметке HTML, обычный текст ошибки (без разметки), даты закрытия, создания и опубликования информации об инциденте, авторе инцидента и метках, присвоенных инциденту (метки типа bug или похожие). Колонки `merge_commit_sha`, `pr_type`, `pr_url` описывают sha мердж-коммита, типа пулл-реквеста (закрывающий, упоминающий, связанный). Колонки `referencing commits not linked to PRs`, `referencing commits linked to PRs`, `closing commits not linked to PRs`, `closing commits linked to PRs`, `closing PRs`, `linked PRs`, `mentioning PRs` и `PRs for referencing commits` содержат информацию вообще обо всех коммитах и пулл-реквестах, упоминавшихся на странице инцидента. Колонки `has mentioning, linked or closing PRs`, `has related commits and PRs` содержат `True` или `False` значения о наличии любых упоминаний об исправлениях на странице данного инцидента (существовании для этого инцидента хотя бы каких-то исправлений в виде пулл-реквестов и коммитов).\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-rwanda",
   "metadata": {},
   "source": [
    "Колонка `source code and errors` содержит весьма полезную информацию о различных секциях в описании инцидента, таких как секции с исходным кодом (часто воспроизводящим ошибку), а также секции с описанием ошибок (traceback). Вообще HTML-разметка с текстом инцидента (колонка `bodyHTML`) содержит кроме этой информации также много другой. Полезность HTML-разметки как раз и состоит в том, что различные секции выделены с помощью специальных ключевых слов и символов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-prime",
   "metadata": {},
   "source": [
    "Колонки `keyword closing PRs`, `non-closing PRs`, `relevant non-closing PRs`, `all relevant PRs`, `most relevant PRs`, `keyword closing commits`, `non-closing commits`, `relevant non-closing commits` и `all relevant commits` содержат все наиболее релевантные инциденту пулл-реквесты и коммиты. Точнее, есть закрывающие инцидент коммиты и пулл-реквесты, которые наиболее релевантны, а также коммиты и пулл-реквесты, закрывающие инцидент посредством ключевых слов в своем сообщении (в GitHub имеется соглашение о том, какие слова нужно писать в описании пулл-реквеста или коммита для того чтобы при слиянии (мердж) пулл-реквеста или коммита происходило автоматическое закрытие инцидента). Среди остальных коммитов и пулл-реквестов также выделяются релевантные и наиболее релевантные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-perry",
   "metadata": {},
   "source": [
    "Датасет включает в себя исправления только для тех инцидентов, которые содержат в своем сообщении отчет traceback. Поэтому в колонке `full_traceback` представлен полный текст этого отчета, а в колонке `traceback_type` - только тип ошибки, описанной в этом отчете."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-martin",
   "metadata": {},
   "source": [
    "Далее, колонки `before_merge_without_docstrings` и `after_merge_without_docstrings` содержат текст сниппетов до и после исправления, из которых удалены докстринги и комментарии. Кроме того, колонки `before_merge_docstrings` и `after_merge_docstrings` содержат тексты докстрингов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-tragedy",
   "metadata": {},
   "source": [
    "Наконец, колонки `path_to_snippet_before_merge` и `path_to_snippet_after_merge` содержат пути к файлам с текстом сниппетов относительно папки. Здесь указывается подпапка `buggy_snippets_files` а затем имя файла с указанием типа `before` или `after`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-samba",
   "metadata": {},
   "source": [
    "Рассмотрим содержимое колонки `most relevant PRs`. Здесь указана вся информация о наиболее релевантных данному инциденту пулл-реквестах. Для каждого пулл-реквеста дается информация обо всех инцидентах, которые относятся к данному пулл-реквесту (`'linked_issues`), включая 10 токенов, предшествующих упоминанию ссылки на инцидент в тексте пулл-реквеста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "better-category",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headRefOid': 'e94b48b88fc3b36eb58bd3b654222d4f99a16b73',\n",
       "  'baseRefOid': '179623480e7b3eabd51c88782dac00a5319c22aa',\n",
       "  'title': 'Protect against non-JSON output from repo2docker',\n",
       "  'bodyHTML': '<p>use the raw line as the message if it’s not JSON</p>\\n<p><span class=\"issue-keyword tooltipped tooltipped-se\" aria-label=\"This pull request closes issue #164.\">closes</span> <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"262988294\" data-permission-text=\"Title is private\" data-url=\"https://github.com/jupyterhub/binderhub/issues/164\" data-hovercard-type=\"issue\" data-hovercard-url=\"/jupyterhub/binderhub/issues/164/hovercard\" href=\"https://github.com/jupyterhub/binderhub/issues/164\">#164</a></p>',\n",
       "  'createdAt': '2017-10-17T11:49:52Z',\n",
       "  'closed': True,\n",
       "  'url': 'https://github.com/jupyterhub/binderhub/pull/185',\n",
       "  'state': 'MERGED',\n",
       "  'merged': True,\n",
       "  'mergedAt': '2017-10-17T14:44:28Z',\n",
       "  'mergedBy': {'login': 'yuvipanda'},\n",
       "  'milestone': None,\n",
       "  'author': {'login': 'minrk'},\n",
       "  'changedFiles': 1,\n",
       "  'closedAt': '2017-10-17T14:44:28Z',\n",
       "  'commits': {'edges': [{'node': {'commit': {'commitUrl': 'https://github.com/jupyterhub/binderhub/commit/e94b48b88fc3b36eb58bd3b654222d4f99a16b73',\n",
       "       'messageBodyHTML': 'use the raw line as the message if it’s not JSON',\n",
       "       'messageHeadline': 'Protect against non-JSON output from repo2docker',\n",
       "       'status': {'state': 'SUCCESS'}}}}]},\n",
       "  'isCrossRepository': True,\n",
       "  'labels': {'edges': []},\n",
       "  'mergeCommit': {'commitUrl': 'https://github.com/jupyterhub/binderhub/commit/d7edb043daaac335e0b6b1d11f4cd8d191b97918',\n",
       "   'messageBodyHTML': 'Protect against non-JSON output from repo2docker',\n",
       "   'messageHeadline': 'Merge pull request #185 from minrk/avoid-failure',\n",
       "   'status': {'state': 'SUCCESS'}},\n",
       "  'linked_issues': {'https://github.com/jupyterhub/binderhub/issues/164': [['raw',\n",
       "     'line',\n",
       "     'as',\n",
       "     'the',\n",
       "     'message',\n",
       "     'if',\n",
       "     'it’s',\n",
       "     'not',\n",
       "     'json',\n",
       "     'closes']]}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfixes_train.at[2568, 'most relevant PRs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-curve",
   "metadata": {},
   "source": [
    "# Загрузка тестового датасета с кодом с ошибками\n",
    "\n",
    "Загрузим тестовый (валидированный) датасет с кодом с ошибками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "governing-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "bugfixes_test = pd.read_pickle(path_to_buggy_data + 'bugfixes_test.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-house",
   "metadata": {},
   "source": [
    "# Описание тестового датасета с кодом с ошибками\n",
    "\n",
    "Посмотрим на колонки этого датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moderate-express",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['before_merge', 'after_merge', 'url', 'bug type', 'bug description',\n",
       "       'bug filename', 'bug function_name', 'bug lines', 'full_traceback',\n",
       "       'traceback_type', 'path_to_snippet_before_merge',\n",
       "       'path_to_snippet_after_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfixes_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-criminal",
   "metadata": {},
   "source": [
    "Кроме обычных колонок `before_merge`, `after_merge` и `url` с текстом сниппетов и ссылкой на инцидент, соответствующий этому исправлению, с именем файла (колонка `bug filename`), а также c именем функции или метода `bug function_name`, с описанием ошибки (колонки `full_traceback` и `traceback_type`), а также с путями к файлам с текстом сниппетов (колонки `path_to_snippet_before_merge` и `path_to_snippet_after_merge`), в датасете содержатся колонки с подтверждениями того факта, что в сниппетах действительно содержатся ошибки. Это колонки с описанием ошибки на естественном языке (колонка `bug description`), понятно объясняющем в чем состоит исправляемая ошибка, колонка `bug type` с типом ошибки согласно классификации [CWE](http://cwe.mitre.org/data/definitions/1000.html), а также колонка `bug lines` с локализацией ошибки (диапазоны номеров строк в формате x,y - строки с x по y. Разделитель в виде ; используется для разделения диапазонов. Одно число x соответствует ситуации, когда ошибка локализована в одной строке)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educational-russia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before_merge</th>\n",
       "      <th>after_merge</th>\n",
       "      <th>url</th>\n",
       "      <th>bug type</th>\n",
       "      <th>bug description</th>\n",
       "      <th>bug filename</th>\n",
       "      <th>bug function_name</th>\n",
       "      <th>bug lines</th>\n",
       "      <th>full_traceback</th>\n",
       "      <th>traceback_type</th>\n",
       "      <th>path_to_snippet_before_merge</th>\n",
       "      <th>path_to_snippet_after_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353547</th>\n",
       "      <td>def remove_lb_backend_address_pool_address(cmd...</td>\n",
       "      <td>def remove_lb_backend_address_pool_address(cmd...</td>\n",
       "      <td>https://github.com/Azure/azure-cli/issues/14342</td>\n",
       "      <td>CWE-248: Uncaught Exception</td>\n",
       "      <td>Uncaught Exception when adding an address to a...</td>\n",
       "      <td>src/azure-cli/azure/cli/command_modules/networ...</td>\n",
       "      <td>remove_lb_backend_address_pool_address</td>\n",
       "      <td>[5]</td>\n",
       "      <td>john@Azure:~$ az network lb address-pool addre...</td>\n",
       "      <td>AttributeError</td>\n",
       "      <td>buggy_snippets_files/3bb7f7f09145626ed3e4ae2d9...</td>\n",
       "      <td>buggy_snippets_files/3bb7f7f09145626ed3e4ae2d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355403</th>\n",
       "      <td>def split_action(arguments):\\n        clas...</td>\n",
       "      <td>def split_action(arguments):\\n        clas...</td>\n",
       "      <td>https://github.com/Azure/azure-cli/issues/793</td>\n",
       "      <td>CWE-754: Improper Check for Unusual or Excepti...</td>\n",
       "      <td>Attribute `arg.name` of `namespace` can be a s...</td>\n",
       "      <td>src/azure-cli-core/azure/cli/core/commands/arm.py</td>\n",
       "      <td>add_id_parameters.split_action</td>\n",
       "      <td>[16]</td>\n",
       "      <td>'str' object has no attribute 'append'\\nTraceb...</td>\n",
       "      <td>AttributeError</td>\n",
       "      <td>buggy_snippets_files/25709cdb193f8c883c904614a...</td>\n",
       "      <td>buggy_snippets_files/25709cdb193f8c883c904614a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379188</th>\n",
       "      <td>def parse_series(self, data, **kwargs):\\n ...</td>\n",
       "      <td>def parse_series(self, data, **kwargs):\\n ...</td>\n",
       "      <td>https://github.com/Flexget/Flexget/issues/2276</td>\n",
       "      <td>CWE-754: Improper Check for Unusual or Excepti...</td>\n",
       "      <td>`guess_result.get('title')` can return None, t...</td>\n",
       "      <td>flexget/plugins/parsers/parser_guessit.py</td>\n",
       "      <td>ParserGuessit.parse_series</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-10 19:39 DEBUG    parser_guessit movin...</td>\n",
       "      <td>AttributeError</td>\n",
       "      <td>buggy_snippets_files/f652403f87adbfe2ca2690e2d...</td>\n",
       "      <td>buggy_snippets_files/f652403f87adbfe2ca2690e2d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99259</th>\n",
       "      <td>def __init__(self, **kwargs):\\n        # S...</td>\n",
       "      <td>def __init__(self, **kwargs):\\n        # S...</td>\n",
       "      <td>https://github.com/GenericMappingTools/pygmt/i...</td>\n",
       "      <td>CWE-754: Improper Check for Unusual or Excepti...</td>\n",
       "      <td>There can be no value for key in default. No c...</td>\n",
       "      <td>pygmt/modules.py</td>\n",
       "      <td>config.__init__</td>\n",
       "      <td>[6]</td>\n",
       "      <td>pygmt-session [ERROR]: Syntax error: Unrecogni...</td>\n",
       "      <td>pygmt.exceptions.GMTCLibError</td>\n",
       "      <td>buggy_snippets_files/db65c0082d70560caaba4022d...</td>\n",
       "      <td>buggy_snippets_files/db65c0082d70560caaba4022d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403629</th>\n",
       "      <td>def dump_checkpoint(self, weights_only: bo...</td>\n",
       "      <td>def dump_checkpoint(self, weights_only: bo...</td>\n",
       "      <td>https://github.com/PyTorchLightning/pytorch-li...</td>\n",
       "      <td>CWE-754: Improper Check for Unusual or Excepti...</td>\n",
       "      <td>There is no check if scaler is None</td>\n",
       "      <td>pytorch_lightning/trainer/training_io.py</td>\n",
       "      <td>TrainerIOMixin.dump_checkpoint</td>\n",
       "      <td>[46]</td>\n",
       "      <td>Running command:\\npython pipe/train_cnn.py\\n/h...</td>\n",
       "      <td>AttributeError</td>\n",
       "      <td>buggy_snippets_files/9e8ea084968f1648a3f76bc45...</td>\n",
       "      <td>buggy_snippets_files/9e8ea084968f1648a3f76bc45...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             before_merge  \\\n",
       "353547  def remove_lb_backend_address_pool_address(cmd...   \n",
       "355403      def split_action(arguments):\\n        clas...   \n",
       "379188      def parse_series(self, data, **kwargs):\\n ...   \n",
       "99259       def __init__(self, **kwargs):\\n        # S...   \n",
       "403629      def dump_checkpoint(self, weights_only: bo...   \n",
       "\n",
       "                                              after_merge  \\\n",
       "353547  def remove_lb_backend_address_pool_address(cmd...   \n",
       "355403      def split_action(arguments):\\n        clas...   \n",
       "379188      def parse_series(self, data, **kwargs):\\n ...   \n",
       "99259       def __init__(self, **kwargs):\\n        # S...   \n",
       "403629      def dump_checkpoint(self, weights_only: bo...   \n",
       "\n",
       "                                                      url  \\\n",
       "353547    https://github.com/Azure/azure-cli/issues/14342   \n",
       "355403      https://github.com/Azure/azure-cli/issues/793   \n",
       "379188     https://github.com/Flexget/Flexget/issues/2276   \n",
       "99259   https://github.com/GenericMappingTools/pygmt/i...   \n",
       "403629  https://github.com/PyTorchLightning/pytorch-li...   \n",
       "\n",
       "                                                 bug type  \\\n",
       "353547                        CWE-248: Uncaught Exception   \n",
       "355403  CWE-754: Improper Check for Unusual or Excepti...   \n",
       "379188  CWE-754: Improper Check for Unusual or Excepti...   \n",
       "99259   CWE-754: Improper Check for Unusual or Excepti...   \n",
       "403629  CWE-754: Improper Check for Unusual or Excepti...   \n",
       "\n",
       "                                          bug description  \\\n",
       "353547  Uncaught Exception when adding an address to a...   \n",
       "355403  Attribute `arg.name` of `namespace` can be a s...   \n",
       "379188  `guess_result.get('title')` can return None, t...   \n",
       "99259   There can be no value for key in default. No c...   \n",
       "403629                There is no check if scaler is None   \n",
       "\n",
       "                                             bug filename  \\\n",
       "353547  src/azure-cli/azure/cli/command_modules/networ...   \n",
       "355403  src/azure-cli-core/azure/cli/core/commands/arm.py   \n",
       "379188          flexget/plugins/parsers/parser_guessit.py   \n",
       "99259                                    pygmt/modules.py   \n",
       "403629           pytorch_lightning/trainer/training_io.py   \n",
       "\n",
       "                             bug function_name bug lines  \\\n",
       "353547  remove_lb_backend_address_pool_address       [5]   \n",
       "355403          add_id_parameters.split_action      [16]   \n",
       "379188              ParserGuessit.parse_series       NaN   \n",
       "99259                          config.__init__       [6]   \n",
       "403629          TrainerIOMixin.dump_checkpoint      [46]   \n",
       "\n",
       "                                           full_traceback  \\\n",
       "353547  john@Azure:~$ az network lb address-pool addre...   \n",
       "355403  'str' object has no attribute 'append'\\nTraceb...   \n",
       "379188  2018-12-10 19:39 DEBUG    parser_guessit movin...   \n",
       "99259   pygmt-session [ERROR]: Syntax error: Unrecogni...   \n",
       "403629  Running command:\\npython pipe/train_cnn.py\\n/h...   \n",
       "\n",
       "                       traceback_type  \\\n",
       "353547                 AttributeError   \n",
       "355403                 AttributeError   \n",
       "379188                 AttributeError   \n",
       "99259   pygmt.exceptions.GMTCLibError   \n",
       "403629                 AttributeError   \n",
       "\n",
       "                             path_to_snippet_before_merge  \\\n",
       "353547  buggy_snippets_files/3bb7f7f09145626ed3e4ae2d9...   \n",
       "355403  buggy_snippets_files/25709cdb193f8c883c904614a...   \n",
       "379188  buggy_snippets_files/f652403f87adbfe2ca2690e2d...   \n",
       "99259   buggy_snippets_files/db65c0082d70560caaba4022d...   \n",
       "403629  buggy_snippets_files/9e8ea084968f1648a3f76bc45...   \n",
       "\n",
       "                              path_to_snippet_after_merge  \n",
       "353547  buggy_snippets_files/3bb7f7f09145626ed3e4ae2d9...  \n",
       "355403  buggy_snippets_files/25709cdb193f8c883c904614a...  \n",
       "379188  buggy_snippets_files/f652403f87adbfe2ca2690e2d...  \n",
       "99259   buggy_snippets_files/db65c0082d70560caaba4022d...  \n",
       "403629  buggy_snippets_files/9e8ea084968f1648a3f76bc45...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugfixes_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-brighton",
   "metadata": {},
   "source": [
    "# Загрузка обучающего датасета с корректным кодом\n",
    "\n",
    "Загрузим обучающую выборку датасета с корректным кодом. Датасет по размеру большой, может не влезть в память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vulnerable-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_stable_data = '/home/kks/zephyr_data/stable_code/'\n",
    "correct_code_train = pd.read_pickle(path_to_stable_data + 'correct_source_code_train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-accuracy",
   "metadata": {},
   "source": [
    "# Описание обучающего датасета с корректным кодом\n",
    "\n",
    "Посмотрим на колонки фрейма, содержащего информацию о корректном коде из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retired-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['before_merge', 'repo_name', 'filename', 'function_name',\n",
       "       'syntax_correct', 'before_merge_without_docstrings',\n",
       "       'before_merge_docstrings', 'path_to_snippet_before_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_code_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-dominant",
   "metadata": {},
   "source": [
    "Колонка `before_merge` содержит исходный текст корректного сниппета, колонка `repo_name` дает название репозитория, из которого взят сниппет, колонки `filename` и `function_name` содержат название файла, содержащего этот сниппет, а также имя функции/метода для этого сниппета. Колонка `syntax_correct` содержит `True` значения о синтаксической корректности сниппетов. Колонка `before_merge_without_docstrings` содержит текст сниппета, из которого удалены докстринги и комментарии, а колонка `before_merge_docstrings` - список докстрингов для этого сниппета. Кроме того колонка `path_to_snippet_before_merge` содержит путь до файла с текстом сниппета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faced-village",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before_merge</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>filename</th>\n",
       "      <th>function_name</th>\n",
       "      <th>syntax_correct</th>\n",
       "      <th>before_merge_without_docstrings</th>\n",
       "      <th>before_merge_docstrings</th>\n",
       "      <th>path_to_snippet_before_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def raw_serialize(self):\\n        result =...</td>\n",
       "      <td>jimmysong_programmingbitcoin</td>\n",
       "      <td>code-ch06_script.py</td>\n",
       "      <td>raw_serialize</td>\n",
       "      <td>True</td>\n",
       "      <td>def raw_serialize(self):\\n        result =...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/7869c9c9e1078ab64439fb57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def serialize(self):\\n        result = sel...</td>\n",
       "      <td>jimmysong_programmingbitcoin</td>\n",
       "      <td>code-ch06_script.py</td>\n",
       "      <td>serialize</td>\n",
       "      <td>True</td>\n",
       "      <td>def serialize(self):\\n        result = sel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/83bf747364a6d298d98825bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def evaluate(self, z):\\n        cmds = sel...</td>\n",
       "      <td>jimmysong_programmingbitcoin</td>\n",
       "      <td>code-ch06_script.py</td>\n",
       "      <td>evaluate</td>\n",
       "      <td>True</td>\n",
       "      <td>def evaluate(self, z):\\n        cmds = sel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/a3bb529ac1f839e50b81f5d7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>def run(test):\\n    suite = TestSuite()\\n    s...</td>\n",
       "      <td>jimmysong_programmingbitcoin</td>\n",
       "      <td>code-ch11_helper.py</td>\n",
       "      <td>run</td>\n",
       "      <td>True</td>\n",
       "      <td>def run(test):\\n    suite = TestSuite()\\n    s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/12442b368e47412505e2a0f9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>def hash160(s):\\n    '''sha256 followed by rip...</td>\n",
       "      <td>jimmysong_programmingbitcoin</td>\n",
       "      <td>code-ch11_helper.py</td>\n",
       "      <td>hash160</td>\n",
       "      <td>True</td>\n",
       "      <td>def hash160(s):\\n    \\n    return hashlib.new(...</td>\n",
       "      <td>[sha256 followed by ripemd160]</td>\n",
       "      <td>stable_snippets_files/1904413ca699feba02ca6a1c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        before_merge  \\\n",
       "0      def raw_serialize(self):\\n        result =...   \n",
       "1      def serialize(self):\\n        result = sel...   \n",
       "2      def evaluate(self, z):\\n        cmds = sel...   \n",
       "5  def run(test):\\n    suite = TestSuite()\\n    s...   \n",
       "6  def hash160(s):\\n    '''sha256 followed by rip...   \n",
       "\n",
       "                      repo_name             filename  function_name  \\\n",
       "0  jimmysong_programmingbitcoin  code-ch06_script.py  raw_serialize   \n",
       "1  jimmysong_programmingbitcoin  code-ch06_script.py      serialize   \n",
       "2  jimmysong_programmingbitcoin  code-ch06_script.py       evaluate   \n",
       "5  jimmysong_programmingbitcoin  code-ch11_helper.py            run   \n",
       "6  jimmysong_programmingbitcoin  code-ch11_helper.py        hash160   \n",
       "\n",
       "   syntax_correct                    before_merge_without_docstrings  \\\n",
       "0            True      def raw_serialize(self):\\n        result =...   \n",
       "1            True      def serialize(self):\\n        result = sel...   \n",
       "2            True      def evaluate(self, z):\\n        cmds = sel...   \n",
       "5            True  def run(test):\\n    suite = TestSuite()\\n    s...   \n",
       "6            True  def hash160(s):\\n    \\n    return hashlib.new(...   \n",
       "\n",
       "          before_merge_docstrings  \\\n",
       "0                              []   \n",
       "1                              []   \n",
       "2                              []   \n",
       "5                              []   \n",
       "6  [sha256 followed by ripemd160]   \n",
       "\n",
       "                        path_to_snippet_before_merge  \n",
       "0  stable_snippets_files/7869c9c9e1078ab64439fb57...  \n",
       "1  stable_snippets_files/83bf747364a6d298d98825bb...  \n",
       "2  stable_snippets_files/a3bb529ac1f839e50b81f5d7...  \n",
       "5  stable_snippets_files/12442b368e47412505e2a0f9...  \n",
       "6  stable_snippets_files/1904413ca699feba02ca6a1c...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_code_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-neutral",
   "metadata": {},
   "source": [
    "# Загрузка тестового датасета с корректным кодом\n",
    "\n",
    "Загрузим тестовый (валидированный) датасет с корректным кодом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valid-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_code_test = pd.read_pickle(path_to_stable_data + 'correct_source_code_test.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-canberra",
   "metadata": {},
   "source": [
    "# Описание тестового датасета с корректным кодом\n",
    "\n",
    "Датасет содержит ту же информацию по отобранным в него сниппетам, что и описанный выше датасет с обучающей выборкой. Сниппеты вошедшие в тестовый датасет отобраны автоматически, а не вручную, как в случае с тестовым датасетом, содержащим код с ошибками. А именно в тестовый датасет с корректным кодом вошли сниппеты не менявшиеся не менее, чем 100 коммитов относительно каталога, где они содержатся. Кроме того, эти сниппеты часто вызываются из реализаций других часто вызываемых сниппетов внутри того же репозитория."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smart-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before_merge</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>filename</th>\n",
       "      <th>function_name</th>\n",
       "      <th>syntax_correct</th>\n",
       "      <th>before_merge_without_docstrings</th>\n",
       "      <th>before_merge_docstrings</th>\n",
       "      <th>path_to_snippet_before_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def user_follows():\\n    access_token = reques...</td>\n",
       "      <td>facebookarchive_python-instagram</td>\n",
       "      <td>sample_app.py</td>\n",
       "      <td>user_follows</td>\n",
       "      <td>True</td>\n",
       "      <td>def user_follows():\\n    access_token = reques...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/e56b911b5f2cf21fcc087a2d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def instrumented_stage(args, stage):\\n    \"\"\"\\...</td>\n",
       "      <td>ClangBuiltLinux_tc-build</td>\n",
       "      <td>build-llvm.py</td>\n",
       "      <td>instrumented_stage</td>\n",
       "      <td>True</td>\n",
       "      <td>def instrumented_stage(args, stage):\\n    \\n  ...</td>\n",
       "      <td>[Returns true if we are using PGO and on stage...</td>\n",
       "      <td>stable_snippets_files/a45224293585c24940ddf7e3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def ev_collect(ev, level, obj):\\n    if isinst...</td>\n",
       "      <td>andikleen_pmu-tools</td>\n",
       "      <td>toplev.py</td>\n",
       "      <td>ev_collect</td>\n",
       "      <td>True</td>\n",
       "      <td>def ev_collect(ev, level, obj):\\n    if isinst...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/759e99ada074389fef8c7f21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def load_libc_args():\\n    # load libc functio...</td>\n",
       "      <td>hugsy_gef</td>\n",
       "      <td>gef.py</td>\n",
       "      <td>load_libc_args</td>\n",
       "      <td>True</td>\n",
       "      <td>def load_libc_args():\\n    \\n    if not get_ge...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/ab1a12c03f2ad8ead19ce1e5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def get_curr_connects_count():\\n    global use...</td>\n",
       "      <td>alexbers_mtprotoproxy</td>\n",
       "      <td>mtprotoproxy.py</td>\n",
       "      <td>get_curr_connects_count</td>\n",
       "      <td>True</td>\n",
       "      <td>def get_curr_connects_count():\\n    global use...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/f9aad12115156a3b3162feda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>def get_junk_item(count=1):\\n    ret_junk = []...</td>\n",
       "      <td>AmazingAmpharos_OoT-Randomizer</td>\n",
       "      <td>ItemList.py</td>\n",
       "      <td>get_junk_item</td>\n",
       "      <td>True</td>\n",
       "      <td>def get_junk_item(count=1):\\n    ret_junk = []...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/aa1413a9b9b2c78a906c82d5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>def is_idle(cpus, idle_keys):\\n    return all(...</td>\n",
       "      <td>andikleen_pmu-tools</td>\n",
       "      <td>toplev.py</td>\n",
       "      <td>is_idle</td>\n",
       "      <td>True</td>\n",
       "      <td>def is_idle(cpus, idle_keys):\\n    return all(...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/33e1c61199b64686481abc05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>def parole_crawl(path, processfn, debug_sgm_li...</td>\n",
       "      <td>gooofy_zamia-speech</td>\n",
       "      <td>parole.py</td>\n",
       "      <td>parole_crawl</td>\n",
       "      <td>True</td>\n",
       "      <td>def parole_crawl(path, processfn, debug_sgm_li...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/54b52d91e62bf4271958db45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>def _set_version(version):\\n    if not version...</td>\n",
       "      <td>ashishb_adb-enhanced</td>\n",
       "      <td>release.py</td>\n",
       "      <td>_set_version</td>\n",
       "      <td>True</td>\n",
       "      <td>def _set_version(version):\\n    if not version...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/0487d88e2b8f7937cf482f9b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>def get_item(items, index, default=None):\\n   ...</td>\n",
       "      <td>hhatto_autopep8</td>\n",
       "      <td>autopep8.py</td>\n",
       "      <td>get_item</td>\n",
       "      <td>True</td>\n",
       "      <td>def get_item(items, index, default=None):\\n   ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>stable_snippets_files/efafca71580f0d9c1e7e8605...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          before_merge  \\\n",
       "0    def user_follows():\\n    access_token = reques...   \n",
       "1    def instrumented_stage(args, stage):\\n    \"\"\"\\...   \n",
       "2    def ev_collect(ev, level, obj):\\n    if isinst...   \n",
       "3    def load_libc_args():\\n    # load libc functio...   \n",
       "4    def get_curr_connects_count():\\n    global use...   \n",
       "..                                                 ...   \n",
       "165  def get_junk_item(count=1):\\n    ret_junk = []...   \n",
       "166  def is_idle(cpus, idle_keys):\\n    return all(...   \n",
       "167  def parole_crawl(path, processfn, debug_sgm_li...   \n",
       "168  def _set_version(version):\\n    if not version...   \n",
       "169  def get_item(items, index, default=None):\\n   ...   \n",
       "\n",
       "                            repo_name         filename  \\\n",
       "0    facebookarchive_python-instagram    sample_app.py   \n",
       "1            ClangBuiltLinux_tc-build    build-llvm.py   \n",
       "2                 andikleen_pmu-tools        toplev.py   \n",
       "3                           hugsy_gef           gef.py   \n",
       "4               alexbers_mtprotoproxy  mtprotoproxy.py   \n",
       "..                                ...              ...   \n",
       "165    AmazingAmpharos_OoT-Randomizer      ItemList.py   \n",
       "166               andikleen_pmu-tools        toplev.py   \n",
       "167               gooofy_zamia-speech        parole.py   \n",
       "168              ashishb_adb-enhanced       release.py   \n",
       "169                   hhatto_autopep8      autopep8.py   \n",
       "\n",
       "               function_name  syntax_correct  \\\n",
       "0               user_follows            True   \n",
       "1         instrumented_stage            True   \n",
       "2                 ev_collect            True   \n",
       "3             load_libc_args            True   \n",
       "4    get_curr_connects_count            True   \n",
       "..                       ...             ...   \n",
       "165            get_junk_item            True   \n",
       "166                  is_idle            True   \n",
       "167             parole_crawl            True   \n",
       "168             _set_version            True   \n",
       "169                 get_item            True   \n",
       "\n",
       "                       before_merge_without_docstrings  \\\n",
       "0    def user_follows():\\n    access_token = reques...   \n",
       "1    def instrumented_stage(args, stage):\\n    \\n  ...   \n",
       "2    def ev_collect(ev, level, obj):\\n    if isinst...   \n",
       "3    def load_libc_args():\\n    \\n    if not get_ge...   \n",
       "4    def get_curr_connects_count():\\n    global use...   \n",
       "..                                                 ...   \n",
       "165  def get_junk_item(count=1):\\n    ret_junk = []...   \n",
       "166  def is_idle(cpus, idle_keys):\\n    return all(...   \n",
       "167  def parole_crawl(path, processfn, debug_sgm_li...   \n",
       "168  def _set_version(version):\\n    if not version...   \n",
       "169  def get_item(items, index, default=None):\\n   ...   \n",
       "\n",
       "                               before_merge_docstrings  \\\n",
       "0                                                   []   \n",
       "1    [Returns true if we are using PGO and on stage...   \n",
       "2                                                   []   \n",
       "3                                                   []   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "165                                                 []   \n",
       "166                                                 []   \n",
       "167                                                 []   \n",
       "168                                                 []   \n",
       "169                                                 []   \n",
       "\n",
       "                          path_to_snippet_before_merge  \n",
       "0    stable_snippets_files/e56b911b5f2cf21fcc087a2d...  \n",
       "1    stable_snippets_files/a45224293585c24940ddf7e3...  \n",
       "2    stable_snippets_files/759e99ada074389fef8c7f21...  \n",
       "3    stable_snippets_files/ab1a12c03f2ad8ead19ce1e5...  \n",
       "4    stable_snippets_files/f9aad12115156a3b3162feda...  \n",
       "..                                                 ...  \n",
       "165  stable_snippets_files/aa1413a9b9b2c78a906c82d5...  \n",
       "166  stable_snippets_files/33e1c61199b64686481abc05...  \n",
       "167  stable_snippets_files/54b52d91e62bf4271958db45...  \n",
       "168  stable_snippets_files/0487d88e2b8f7937cf482f9b...  \n",
       "169  stable_snippets_files/efafca71580f0d9c1e7e8605...  \n",
       "\n",
       "[170 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_code_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-officer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
