|title|url|
|------|-----------------------|
| S.  Wang,  T.  Liu,  J.  Nam,  and  L.  Tan,  “Deep  Semantic Feature Learning for Software Defect Prediction”  TSE,2018                                                                                                       | https://doi.org/10.1109/TSE.2018.2877612 |
| H. K. Dam, T. Tran, T. T. M. Pham, S. W. Ng, J. Grundy,and A. Ghose, “Automatic feature learning for predicting vulnerable software components,”TSE, 2018.                                                                   | https://doi.org/10.1109/TSE.2018.2881961 |
| H.  K.  Dam,  T.  Pham,  S.  W.  Ng,  T.  Tran,  J.  Grundy, A.  Ghose,  T.  Kim,  and  C.-J.  Kim,  “Lessons  learned from using a deep tree-based model for software defect prediction in practice,” inMSR, 2019, p. 4657. | https://doi.org/10.1109/MSR.2019.00017 |
| J.  Zhang,  X.  Wang,  H.  Zhang,  H.  Sun,  K.  Wang,  andX.  Liu,  “A novel neural source code representation based on abstract syntax tree,” inICSE, 2019, pp. 783–794.                                                    | https://doi.org/10.1109/ICSE.2019.00086 |
| T. Hoang, H. Khanh Dam, Y. Kamei, D. Lo, and N. Ubayashi, “Deepjit: An  end-to-end  deep  learning  framework  for  just-in-time  defect  prediction,”  in2019  IEEE/ACM  16th  International  Conference  on  MiningSoftware Repositories (MSR), 2019, pp. 34–45 | https://doi.org/10.1109/MSR.2019.00016 |
| Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning | https://doi.org/10.1016/j.infsof.2017.11.008 |
| LDFR: Learning deep feature representation for software defect prediction | https://doi.org/10.1016/j.jss.2019.110402 |
| Software defect prediction via cost-sensitive Siamese parallel fully-connected neural networks | https://doi.org/10.1016/j.neucom.2019.03.076 |
| Deep Learning for Just-in-Time Defect Prediction | https://doi.org/10.1109/QRS.2015.14 |
| TLEL: A two-layer ensemble learning approach for just-in-time defect prediction | https://doi.org/10.1016/j.infsof.2017.03.007 |
| Improving defect prediction with deep forest | https://doi.org/10.1016/j.infsof.2019.07.003 |

Представления
|title|url|
|------|-----------------------|
| Novel positional encodings to enable tree-based transformers | https://papers.nips.cc/paper/2019/file/6e0917469214d8fbd8c517dcdc6b8dcf-Paper.pdf |
| Improved Semantic Representations FromTree-Structured Long Short-Term Memory Networks | https://arxiv.org/pdf/1503.00075.pdf |
| Anomaly Detection Using Autoencoders with Nonlinear Dimensionality Reduction | https://doi.org/10.1145/3291636 |
| Learning and Evaluating Contextual Embedding of Source Code | http://proceedings.mlr.press/v119/kanade20a.html |

Не подходит по теме/методам
|title|url|
|------|-----------------------|
| An Ensemble DeepBoost Classifier for Software Defect Prediction |  http://www.warse.org/IJATCSE/static/pdf/file/ijatcse173922020.pdf |
| An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models |  https://doi.org/10.1109/TSE.2020.2982385 |
| Predicting Defective Lines Using a Model-Agnostic Technique                    |  https://arxiv.org/pdf/2009.03612.pdf |
| Practitioners’ Perceptions of the Goals and Visual Explanations of Defect Prediction Models | https://arxiv.org/pdf/2102.12007.pdf  |
| Early Life Cycle Software Defect Prediction. Why? How?                     | https://arxiv.org/pdf/2011.13071.pdf |
| Looking for Software Defects? First Find the Nonconformists | https://doi.org/10.1109/SCAM51674.2020.00014 |
| Anomaly Detection Using Autoencoders with Nonlinear Dimensionality Reduction | https://doi.org/10.1145/2689746.2689747 |
| Allamanis et al., “Suggesting accurate method and class names,”inFSE, 2015, pp. 38–49.	                                                                                                                                     | https://doi.org/10.1145/2786805.2786849 |
| Using Large-Scale Anomaly Detection on Code to Improve Kotlin Compiler | https://doi.org/10.1145/3379597.3387447 |
